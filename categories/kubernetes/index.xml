<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>kubernetes on Myki的博客</title><link>https://www.1nth.com/categories/kubernetes/</link><description>Recent content in kubernetes on Myki的博客</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 18 Feb 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://www.1nth.com/categories/kubernetes/index.xml" rel="self" type="application/rss+xml"/><item><title>kube-event通知</title><link>https://www.1nth.com/post/kube-event/</link><pubDate>Fri, 18 Feb 2022 00:00:00 +0000</pubDate><guid>https://www.1nth.com/post/kube-event/</guid><description>&lt;p>k8s事件通知&lt;/p></description></item><item><title>强制删除 Terminating 状态的 namespace</title><link>https://www.1nth.com/post/k8s-delete-namespace/</link><pubDate>Wed, 18 Aug 2021 00:00:00 +0000</pubDate><guid>https://www.1nth.com/post/k8s-delete-namespace/</guid><description>&lt;blockquote>
&lt;p>有时候删除命名空间后，发现命名空间一直处于 Terminating 状态。通过执行 kubectl delete namespace ${namespace} &amp;ndash;force &amp;ndash;grace-period=0 强制删除命令依然无法删除。&lt;/p>
&lt;/blockquote></description></item><item><title>CoreDNS：Kubernetes内部域名解析原理、弊端及优化方式</title><link>https://www.1nth.com/post/k8s-coredns/</link><pubDate>Thu, 03 Jun 2021 00:00:00 +0000</pubDate><guid>https://www.1nth.com/post/k8s-coredns/</guid><description>&lt;p>&lt;img src="https://oss.1nth.com/images/1nth/k8s-coredns.png?x-oss-process=style/dev" alt="ingress_helm3_install">&lt;/p></description></item><item><title>Kubernetes生产中删除资源失败</title><link>https://www.1nth.com/post/k8s-delete-force/</link><pubDate>Wed, 19 May 2021 00:00:00 +0000</pubDate><guid>https://www.1nth.com/post/k8s-delete-force/</guid><description>&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-shell" data-lang="shell">简单说一下原因，一般情况下，刚创建的资源，还未使用的时候删除，肯定可以删除成功。一旦使用了资源，即使将使用了该资源的其他资源一并删除，再来删除该资源，还是失败。类似于当我们的电脑插入u盘时，拔掉之前，你确认你自己没有在使用u盘中的任何内容了，在手动弹出u盘时，还是提示被占用的类似信息。和Kubernetes这个BUG是异曲同工之妙，还是有一些未知的信息在占用着资源。（个人见解，仅供参考）
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>k8s部署openvpn打通k8s网络将Kubernetes集群网络暴露给本地开发网络</title><link>https://www.1nth.com/post/k8s-openvpn/</link><pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate><guid>https://www.1nth.com/post/k8s-openvpn/</guid><description>&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-shell" data-lang="shell">使用OpenVPN将Kubernetes集群网络暴露给本地开发网络
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>yapi部署</title><link>https://www.1nth.com/post/yapi-install-k8s/</link><pubDate>Thu, 25 Mar 2021 00:00:00 +0000</pubDate><guid>https://www.1nth.com/post/yapi-install-k8s/</guid><description>&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-shell" data-lang="shell">起初yapi是单独部署在一台机器上,部署方式docker,最近公司统一账户管理&lt;span class="o">(&lt;/span>openldap&lt;span class="o">)&lt;/span>,所以把yapi部署在k8s里面
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>kubernetes导出</title><link>https://www.1nth.com/post/k8s_yaml_export/</link><pubDate>Thu, 04 Mar 2021 00:00:00 +0000</pubDate><guid>https://www.1nth.com/post/k8s_yaml_export/</guid><description>&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-shell" data-lang="shell">在 k8s 中导出&lt;span class="o">(&lt;/span>kubectl get xx -o yaml&lt;span class="o">)&lt;/span>资源描述信息时，会带出一些k8s系统添加的信息，但这些都不是我们需要的信息，官方没有提供过滤的选项，在下面我给出了几种方式来处理这种情况。
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>使用k8s踩过的坑,优化记录 (持续交作业)</title><link>https://www.1nth.com/post/k8s_issues/</link><pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate><guid>https://www.1nth.com/post/k8s_issues/</guid><description>&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-shell" data-lang="shell">k8s v1.18.3 &lt;span class="o">(&lt;/span>dev 二进制安装&lt;span class="o">)&lt;/span>
k8s v1.19.4 &lt;span class="o">(&lt;/span>线上 kubeadm安装&lt;span class="o">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>基于libfaketime修改容器时间(不修改宿主机)</title><link>https://www.1nth.com/post/pod_time_modify/</link><pubDate>Sun, 07 Feb 2021 00:00:00 +0000</pubDate><guid>https://www.1nth.com/post/pod_time_modify/</guid><description>&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-shell" data-lang="shell">因业务订单需要生成报表需要修改单个k8s的单个pod时间,而且不影响其他业务得使用
之前测试alpine时发现兼容性不好，ubuntu验证正常
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>使用kubectl patch更新API对象</title><link>https://www.1nth.com/post/kubectl_path_update/</link><pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate><guid>https://www.1nth.com/post/kubectl_path_update/</guid><description>&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-shell" data-lang="shell">测试环境因为开发频繁更新pod,直接更新yaml文件感觉太繁琐,
而且因为环境问题既有Jenkins发版,也有gitlab发版
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>linux服务器强制重启</title><link>https://www.1nth.com/post/linux-reboot-force/</link><pubDate>Thu, 24 Dec 2020 00:00:00 +0000</pubDate><guid>https://www.1nth.com/post/linux-reboot-force/</guid><description>&lt;p>Linux使用shutdown -r now 或者 reboot、init 6 命令无法重启时使用以下两条命令可强制重启：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="nb">echo&lt;/span> &lt;span class="m">1&lt;/span> &amp;gt; /proc/sys/kernel/sysrq
&lt;span class="nb">echo&lt;/span> b &amp;gt; /proc/sysrq-trigger
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>k8s服务调用报错MessageForbidden!Configured service account doesnt have access</title><link>https://www.1nth.com/post/k8s-sa-java/</link><pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate><guid>https://www.1nth.com/post/k8s-sa-java/</guid><description>&lt;p>将微服务部署在k8s中，使用k8s的服务发现调用另外一个服务的接口&lt;/p>
&lt;p>2020-11-27 17:09:03,473 WARN org.springframework.cloud.kubernetes.StandardPodUtils (StandardPodUtils.java:79)- Failed to get pod with name:[hotel-qunar-api-7cc9d4dd7b-qbn5c]. You should look into this if things aren&amp;rsquo;t working as you expect. Are you missing serviceaccount permissions?
io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: GET at: https://10.96.0.1/api/v1/namespaces/hotel/pods/hotel-qunar-api-7cc9d4dd7b-qbn5c. Message: Forbidden!Configured service account doesn&amp;rsquo;t have access. Service account may have been revoked. pods &amp;ldquo;hotel-qunar-api-7cc9d4dd7b-qbn5c&amp;rdquo; is forbidden: User &amp;ldquo;system:serviceaccount:hotel:default&amp;rdquo; cannot get resource &amp;ldquo;pods&amp;rdquo; in API group &amp;quot;&amp;rdquo; in the namespace &amp;ldquo;hotel&amp;rdquo;.&lt;/p></description></item><item><title>K8S部署Kafka(K8S外部可访问) NodePort 集群外访问</title><link>https://www.1nth.com/post/kafka-install-k8s/</link><pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate><guid>https://www.1nth.com/post/kafka-install-k8s/</guid><description>&lt;h4 id="环境信息">环境信息&lt;/h4>
&lt;p>本次实战的操作系统和软件的版本信息如下：&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-Bash" data-lang="Bash">env:
Kubernetes：1.18
Kubernetes宿主机：CentOS Linux release 7.7.1908
NFS服务：IP地址192.168.1.43，动态存储卷 storageClass: &lt;span class="s2">&amp;#34;nfs-client&amp;#34;&lt;/span>
Helm：3.2.2
Kafka：2.0.1
Zookeeper：3.5.5
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>国内拉取google kubernetes镜像 同步镜像sync</title><link>https://www.1nth.com/post/images-sync-travis/</link><pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate><guid>https://www.1nth.com/post/images-sync-travis/</guid><description>&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-fallback" data-lang="fallback">私有仓库拉取kubernetes镜像
同步到dockerhub或者阿里云仓库
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>解决kubernetes:v1.18.9 get cs127.0.0.1 connection refused错误</title><link>https://www.1nth.com/post/k8s-cs-unhealthy/</link><pubDate>Tue, 22 Sep 2020 00:00:00 +0000</pubDate><guid>https://www.1nth.com/post/k8s-cs-unhealthy/</guid><description>&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-fallback" data-lang="fallback">kubectl get cs
NAME STATUS MESSAGE ERROR
scheduler Unhealthy Get http://127.0.0.1:10251/healthz: dial tcp 127.0.0.1:10251: connect: connection refused
controller-manager Unhealthy Get http://127.0.0.1:10252/healthz: dial tcp 127.0.0.1:10252: connect: connection refused
etcd-0 Healthy {&amp;#34;health&amp;#34;:&amp;#34;true&amp;#34;}
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Kubeadm证书过期时间调整</title><link>https://www.1nth.com/post/kubeadm-ssl-update/</link><pubDate>Mon, 21 Sep 2020 00:00:00 +0000</pubDate><guid>https://www.1nth.com/post/kubeadm-ssl-update/</guid><description>&lt;p>&lt;a name="6ed7c9be">&lt;/a>
kubeadm 默认证书为一年，一年过期后，会导致api service不可用，使用过程中会出现：&lt;code>x509: certificate has expired or is not yet valid&lt;/code>&lt;/p></description></item><item><title>kubeadm + Cilium 搭建kubernetes集群</title><link>https://www.1nth.com/post/k8s-network-cilium/</link><pubDate>Sun, 13 Sep 2020 00:00:00 +0000</pubDate><guid>https://www.1nth.com/post/k8s-network-cilium/</guid><description>&lt;p>&lt;a name="6ed7c9be">&lt;/a>&lt;/p>
&lt;h2 id="不得不说的kubeadm">不得不说的kubeadm&lt;/h2>
&lt;p>&lt;br />kubeadm部署很方便,但是是一个老外写的,使用staticPod(容器)运行的管理组件,镜像都是&lt;code>gcr.io&lt;/code>域名仓库里的。&lt;br />域名仓库很多docker的人甚至都不知道,docker镜像命名规则是&lt;code>域名/库名/img_name:tag&lt;/code>这种形式,dockerhub上要拉取镜像直接是&lt;code>库名/img_name:tag&lt;/code>这种名字,是因为域名缺省是&lt;code>docker.io&lt;/code>也就是dockerhub上看到的都是这个域名仓库的&lt;br />常见的域名仓库国外有gcr.io,quay.io,国内的阿里(registry.cn-hangzhou.aliyuncs.com,hangzhou以外还有shenzhen啥的),daocloud.io等等.gcr.io因为位置在国外会拉取不到.国内阿里仓库同步了&lt;code>gcr.io/google_containers&lt;/code>这些镜像,&lt;br />
&lt;br />总有人认为kubeadm的容器运行没有二进制运行放心.容器本身就是个隔离受限的进程,另外管理组件都是无状态的,但是他们总感觉不放心。&lt;br />事实上除了kubelet以外所有组件都可以用容器方式运行,管理组件简单说下就是集群数据存放&lt;code>etcd&lt;/code>数据库里,apiserver去和etcd交互,其他组件和apiserver交互,kubelet调用api去操作docker,其中一些组件也会去操作各个节点的系统设置&lt;br />ererere
&lt;a name="ofRxy">&lt;/a>&lt;/p></description></item><item><title>k8s安装ingress helm3安装ingress ingress配置</title><link>https://www.1nth.com/post/ingress_helm3_install/</link><pubDate>Wed, 26 Aug 2020 00:00:00 +0000</pubDate><guid>https://www.1nth.com/post/ingress_helm3_install/</guid><description>&lt;p>&lt;img src="https://oss.1nth.com/images/1nth/ingress_helm3_install.png?x-oss-process=style/dev" alt="ingress_helm3_install">&lt;/p></description></item><item><title>kubeadm集群备份恢复etcd</title><link>https://www.1nth.com/post/etcd_backup_kubeadm/</link><pubDate>Fri, 21 Aug 2020 00:00:00 +0000</pubDate><guid>https://www.1nth.com/post/etcd_backup_kubeadm/</guid><description>&lt;p>kubeadm集群备份恢复etcd
&lt;img src="https://oss.1nth.com/images/1nth/etcd_backup_kubeadm.jpg?x-oss-process=style/dev" alt="aliyun_vos_vpc">&lt;/p></description></item><item><title>办公环境下 kubernetes 网络互通方案</title><link>https://www.1nth.com/post/office-env-k8s-network/</link><pubDate>Wed, 19 Aug 2020 00:00:00 +0000</pubDate><guid>https://www.1nth.com/post/office-env-k8s-network/</guid><description>&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-fallback" data-lang="fallback"> +--------------------+ +--------------------+
| +------------+ | | +------------+ |
| | | | | | | |
| | ConA | | | | ConB | |
| | | | | | | |
| +-----+------+ | | +-----+------+ |
| |veth | | |veth |
| wl-A | | wl-B |
| | | | | |
+-------node-A-------+ +-------node-B-------+
| | | |
| | type1. in the same lan | |
| +-------------------------------+ |
| |
| type2. in different network |
| +-------------+ |
| | | |
+-------------+ Routers |-------------+
| |
+-------------+
从ConA中发送给ConB的报文被nodeA的wl-A接收，根据nodeA上的路由规则，经过各种iptables规则后，转发到nodeB。
如果nodeA和nodeB在同一个二层网段，下一条地址直接就是node-B，经过二层交换机即可到达。
如果nodeA和nodeB在不同的网段，报文被路由到下一跳，经过三层交换或路由器，一步步跳转到node-B。
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="https://oss.1nth.com/images/1nth/calicoNetwork.png?x-oss-process=style/dev" alt="aliyun_vos_vpc">&lt;/p></description></item></channel></rss>